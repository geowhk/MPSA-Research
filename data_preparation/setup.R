# Loading Packages --------------------------------------------------------

# === MPSA ì—°êµ¬ í”„ë¡œì íŠ¸ í™˜ê²½ ì„¤ì • ===

# ğŸ†• tmap 4.1 ë²„ì „ ìš”êµ¬ì‚¬í•­
# tmap 4.xëŠ” ìƒˆë¡œìš´ ë¬¸ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤
# - tm_fill()ì—ì„œ fill = "var", fill.scale = tm_scale_*(), fill.legend = tm_legend() ì‚¬ìš©
# - tm_layout()ì—ì„œ title.position = c("center", "top") í˜•ì‹ ì‚¬ìš©
# - í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ v3 ìŠ¤íƒ€ì¼ë„ ì§€ì›

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© (tmap 4.1+ í¬í•¨)
required_packages <- c(
  "tidyverse",       # ë°ì´í„° ì¡°ì‘ ë° ì‹œê°í™”
  "sf",              # ê³µê°„ ë°ì´í„° ì²˜ë¦¬
  "spdep",           # ê³µê°„ ê°€ì¤‘ì¹˜ ë° ìê¸°ìƒê´€
  "randomForest",    # Random Forest ë° proximity
  "tmap",            # ê³µê°„ ì‹œê°í™” (4.1+ ë²„ì „)
  "GGally",          # ìƒê´€ê´€ê³„ ì‹œê°í™”
  "psych",           # ê¸°ìˆ í†µê³„
  "MASS",            # ë‹¤ë³€ëŸ‰ í†µê³„
  "pheatmap",        # íˆíŠ¸ë§µ
  "Rtsne",           # t-SNE
  "Matrix",          # í–‰ë ¬ ì—°ì‚°
  "mvtnorm",         # ë‹¤ë³€ëŸ‰ ì •ê·œë¶„í¬ (ë§ˆí• ë¼ë…¸ë¹„ìŠ¤ ê±°ë¦¬ìš©)
  "car",             # ê³ ê¸‰ íšŒê·€ë¶„ì„
  # ê³ ê¸‰ ë¶„ì„ìš© íŒ¨í‚¤ì§€ ì¶”ê°€
  "igraph", "gstat", "spBayes", "patchwork", "broom",
  "viridis", "ggraph", "CompQuadForm"
)

installed <- required_packages %in% installed.packages()
if (any(!installed)) {
  install.packages(required_packages[!installed])
}

# ë¡œë”©
lapply(required_packages, library, character.only = TRUE)

if (!require("vscDebugger")) install.packages("vscDebugger")
if (!require("jsonlite")) install.packages("jsonlite")

if (requireNamespace("conflicted", quietly = TRUE)) {
  library(conflicted)
  conflict_prefer("select", "dplyr")
  conflict_prefer("filter", "dplyr")
  conflict_prefer("mutate", "dplyr")
  # ì¶”ê°€ ì¶©ëŒ í•´ê²°
  conflict_prefer("lag", "dplyr")
  conflict_prefer("union", "dplyr")
}

# === ì‹¤í–‰ ì˜ˆì‹œ ë° ì‹œê°í™” =====================================================

# === 1. ê¸°ë³¸ ë°ì´í„° ì„¤ì • ì‹¤í–‰ ===
# 
# # ì „ì²´ ì„¤ì • ì‹¤í–‰ (ì›ìŠ¤í†±)
# setup_results <- setup_franklin_county_data()
# 
# # ì„¤ì • ê²°ê³¼ í™•ì¸
# print(setup_results$summary)

# === 2. ë‹¨ê³„ë³„ ë°ì´í„° ì¤€ë¹„ (ìƒì„¸) ===
# 
# # Step 1: íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ë¡œë“œ
# install_required_packages()
# 
# # Step 2: ë°ì´í„° ë‹¤ìš´ë¡œë“œ
# franklin_data <- download_franklin_county_data()
# print("ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
# 
# # Step 3: ë°ì´í„° ì „ì²˜ë¦¬
# processed_data <- preprocess_franklin_data(franklin_data)
# print("ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ")
# 
# # Step 4: ë°ì´í„° ì €ì¥
# saveRDS(processed_data, "data/franklin.rds")
# print("ë°ì´í„° ì €ì¥ ì™„ë£Œ")

# === 3. ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ì‹œê°í™” ===
# 
# # ë°ì´í„° ë¡œë“œ
# franklin <- readRDS("data/franklin.rds")
# 
# # ê¸°ë³¸ ì •ë³´ í™•ì¸
# library(ggplot2)
# library(tmap)
# library(dplyr)
# 
# # ë°ì´í„° êµ¬ì¡° ìš”ì•½
# data_summary <- list(
#   n_tracts = nrow(franklin),
#   n_variables = ncol(franklin) - 1,  # geometry ì»¬ëŸ¼ ì œì™¸
#   variable_names = names(franklin)[!names(franklin) %in% "geometry"],
#   data_types = sapply(franklin, class),
#   missing_values = sapply(franklin, function(x) sum(is.na(x)))
# )
# 
# # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ ì¶”ì¶œ
# numeric_data <- franklin %>% 
#   st_drop_geometry() %>% 
#   select(where(is.numeric))
# 
# print(paste("ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê°œìˆ˜:", ncol(numeric_data)))

# === 4. ê¸°ìˆ í†µê³„ëŸ‰ ì‹œê°í™” ===
# 
# # ì£¼ìš” ë³€ìˆ˜ë“¤ì˜ ë¶„í¬ í™•ì¸
# key_variables <- c("total_population", "median_income", "unemployment_rate", 
#                    "poverty_rate", "college_education")
# 
# # ì¡´ì¬í•˜ëŠ” ë³€ìˆ˜ë§Œ ì„ íƒ
# available_vars <- key_variables[key_variables %in% names(franklin)]
# 
# # ë³€ìˆ˜ë³„ íˆìŠ¤í† ê·¸ë¨
# for (var in available_vars) {
#   p <- ggplot(franklin, aes_string(x = var)) +
#     geom_histogram(bins = 30, alpha = 0.7, fill = "steelblue", color = "white") +
#     labs(title = paste("Distribution of", var),
#          x = var, y = "Frequency") +
#     theme_minimal()
#   
#   ggsave(paste0("output/data_exploration/", var, "_distribution.png"), 
#          p, width = 8, height = 6)
# }
# 
# # ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤
# if (length(available_vars) > 1) {
#   cor_matrix <- cor(franklin[available_vars], use = "complete.obs")
#   
#   library(corrplot)
#   png("output/data_exploration/correlation_matrix.png", width = 800, height = 600)
#   corrplot(cor_matrix, method = "color", type = "upper", 
#            order = "hclust", tl.cex = 0.8, tl.col = "black",
#            title = "Correlation Matrix of Key Variables")
#   dev.off()
# }

# === 5. ê³µê°„ ë¶„í¬ ì‹œê°í™” ===
# 
# # ê¸°ë³¸ ì§€ë„
# base_map <- tm_shape(franklin) +
#   tm_borders(col = "gray", alpha = 0.7) +
#   tm_layout(title = "Franklin County Census Tracts",
#             frame = FALSE)
# 
# # ì£¼ìš” ë³€ìˆ˜ë³„ ê³µê°„ ë¶„í¬ ì§€ë„
# for (var in available_vars) {
#   if (var %in% names(franklin)) {
#     spatial_map <- tm_shape(franklin) +
#       tm_fill(var, 
#               title = var,
#               palette = "YlOrRd",
#               style = "quantile",
#               n = 5) +
#       tm_borders(alpha = 0.3, col = "white") +
#       tm_layout(
#         title = paste("Spatial Distribution of", var),
#         legend.position = c("right", "bottom")
#       )
#     
#     tmap_save(spatial_map, 
#               paste0("output/data_exploration/", var, "_spatial.png"))
#   }
# }

# === 6. ë°ì´í„° í’ˆì§ˆ ì§„ë‹¨ ===
# 
# # ê²°ì¸¡ê°’ ë¶„ì„
# missing_analysis <- franklin %>%
#   st_drop_geometry() %>%
#   summarise_all(~ sum(is.na(.))) %>%
#   gather(variable, missing_count) %>%
#   mutate(missing_percentage = round(100 * missing_count / nrow(franklin), 2)) %>%
#   arrange(desc(missing_count))
# 
# # ê²°ì¸¡ê°’ ì‹œê°í™”
# p_missing <- ggplot(missing_analysis, aes(x = reorder(variable, missing_count), y = missing_count)) +
#   geom_col(fill = "coral", alpha = 0.8) +
#   coord_flip() +
#   labs(title = "Missing Values by Variable",
#        x = "Variables", y = "Number of Missing Values") +
#   theme_minimal()
# 
# ggsave("output/data_exploration/missing_values.png", p_missing, width = 10, height = 8)
# 
# # ì´ìƒê°’ ë¶„ì„ (ìˆ˜ì¹˜í˜• ë³€ìˆ˜)
# outlier_analysis <- numeric_data %>%
#   gather(variable, value) %>%
#   group_by(variable) %>%
#   summarise(
#     Q1 = quantile(value, 0.25, na.rm = TRUE),
#     Q3 = quantile(value, 0.75, na.rm = TRUE),
#     IQR = Q3 - Q1,
#     lower_bound = Q1 - 1.5 * IQR,
#     upper_bound = Q3 + 1.5 * IQR,
#     outliers = sum(value < lower_bound | value > upper_bound, na.rm = TRUE),
#     outlier_percentage = round(100 * outliers / n(), 2)
#   ) %>%
#   arrange(desc(outliers))
# 
# # ì´ìƒê°’ ì‹œê°í™”
# p_outliers <- ggplot(outlier_analysis, aes(x = reorder(variable, outliers), y = outliers)) +
#   geom_col(fill = "lightgreen", alpha = 0.8) +
#   coord_flip() +
#   labs(title = "Outliers by Variable (IQR method)",
#        x = "Variables", y = "Number of Outliers") +
#   theme_minimal()
# 
# ggsave("output/data_exploration/outliers_analysis.png", p_outliers, width = 10, height = 8)

# === 7. ê³µê°„ íŠ¹ì„± ë¶„ì„ ===
# 
# # ê³µê°„ ì—°ê²°ì„± ë¶„ì„
# library(spdep)
# 
# # ì¸ì ‘ì„± ê¸°ë°˜ ì´ì›ƒ êµ¬ì¡° ìƒì„±
# coords <- st_coordinates(st_centroid(franklin))
# nb_queen <- poly2nb(franklin, queen = TRUE)
# nb_rook <- poly2nb(franklin, queen = FALSE)
# 
# # ì´ì›ƒ ìˆ˜ ë¶„í¬
# neighbors_analysis <- data.frame(
#   tract_id = 1:length(nb_queen),
#   queen_neighbors = sapply(nb_queen, length),
#   rook_neighbors = sapply(nb_rook, length)
# )
# 
# # ì´ì›ƒ ìˆ˜ ë¶„í¬ ì‹œê°í™”
# p_neighbors <- ggplot(neighbors_analysis) +
#   geom_histogram(aes(x = queen_neighbors), bins = 15, alpha = 0.7, 
#                  fill = "steelblue", color = "white") +
#   labs(title = "Distribution of Number of Neighbors (Queen Contiguity)",
#        x = "Number of Neighbors", y = "Frequency") +
#   theme_minimal()
# 
# ggsave("output/data_exploration/neighbors_distribution.png", p_neighbors, width = 8, height = 6)
# 
# # ê³µê°„ ê°€ì¤‘ì¹˜ í–‰ë ¬ ìƒì„± ë° íŠ¹ì„± ë¶„ì„
# W_matrix <- nb2mat(nb_queen, style = "W", zero.policy = TRUE)
# 
# # ê°€ì¤‘ì¹˜ í–‰ë ¬ íŠ¹ì„±
# W_properties <- list(
#   dimensions = dim(W_matrix),
#   total_connections = sum(W_matrix > 0),
#   average_neighbors = mean(rowSums(W_matrix > 0)),
#   connectivity_range = range(rowSums(W_matrix > 0)),
#   row_sums_check = all(abs(rowSums(W_matrix) - 1) < 1e-10, na.rm = TRUE)
# )
# 
# cat("ê³µê°„ ê°€ì¤‘ì¹˜ í–‰ë ¬ íŠ¹ì„±:\n")
# cat(sprintf("  - ì°¨ì›: %d x %d\n", W_properties$dimensions[1], W_properties$dimensions[2]))
# cat(sprintf("  - ì´ ì—°ê²° ìˆ˜: %d\n", W_properties$total_connections))
# cat(sprintf("  - í‰ê·  ì´ì›ƒ ìˆ˜: %.2f\n", W_properties$average_neighbors))
# cat(sprintf("  - ì´ì›ƒ ìˆ˜ ë²”ìœ„: [%d, %d]\n", W_properties$connectivity_range[1], W_properties$connectivity_range[2]))
# cat(sprintf("  - í–‰ í•©ê³„ = 1 ì¡°ê±´: %s\n", ifelse(W_properties$row_sums_check, "ë§Œì¡±", "ë¶ˆë§Œì¡±")))

# === 8. MPSA ë°©ë²•ë¡  í˜¸í™˜ì„± ê²€ì¦ ===
# 
# # 6ê°œ ë°©ë²•ë¡  í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸
# compatibility_test <- data.frame(
#   Method = c("MPSA", "PCA + Moran's I", "Individual Moran's I", 
#              "Euclidean-based", "LIMSA (Anselin 2019)", "ì´ëª½í˜„(2012) Mahalanobis"),
#   Compatible = c("Yes", "Yes", "Yes", "Yes", "Yes", "Yes"),
#   Requirements = c(
#     "Numeric data, Spatial weights",
#     "Numeric data, Spatial weights", 
#     "Numeric data, Spatial weights",
#     "Numeric data, Spatial weights",
#     "Numeric data, Spatial weights",
#     "Numeric data, Spatial weights"
#   ),
#   Notes = c(
#     "Ready for Random Forest proximity calculation",
#     "Ready for PCA dimension reduction",
#     "Ready for univariate Moran's I calculation",
#     "Ready for distance-based analysis",
#     "Ready for multivariate LISA",
#     "Ready for Mahalanobis distance calculation"
#   )
# )
# 
# # í˜¸í™˜ì„± ê²°ê³¼ ì €ì¥
# write.csv(compatibility_test, "output/data_exploration/method_compatibility.csv", row.names = FALSE)

# === 9. ë°ì´í„° ìš”ì•½ ë³´ê³ ì„œ ìƒì„± ===
# 
# # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
# if (!dir.exists("output/data_exploration")) {
#   dir.create("output/data_exploration", recursive = TRUE)
# }
# 
# # ì¢…í•© ë°ì´í„° ìš”ì•½
# data_report <- list(
#   study_area = "Franklin County, Ohio",
#   n_census_tracts = nrow(franklin),
#   n_variables = ncol(numeric_data),
#   variable_list = names(numeric_data),
#   spatial_properties = W_properties,
#   data_quality = list(
#     total_missing = sum(missing_analysis$missing_count),
#     variables_with_missing = sum(missing_analysis$missing_count > 0),
#     total_outliers = sum(outlier_analysis$outliers, na.rm = TRUE)
#   )
# )
# 
# # JSON í˜•íƒœë¡œ ì €ì¥
# library(jsonlite)
# write_json(data_report, "output/data_exploration/data_summary_report.json", pretty = TRUE)
# 
# # CSV í˜•íƒœ ìš”ì•½ ì €ì¥
# data_summary_csv <- data.frame(
#   Metric = c("Study Area", "Census Tracts", "Variables", "Missing Values", 
#              "Outliers", "Average Neighbors", "Data Quality"),
#   Value = c(
#     data_report$study_area,
#     data_report$n_census_tracts,
#     data_report$n_variables,
#     data_report$data_quality$total_missing,
#     data_report$data_quality$total_outliers,
#     round(data_report$spatial_properties$average_neighbors, 2),
#     "Ready for Analysis"
#   )
# )
# 
# write.csv(data_summary_csv, "output/data_exploration/data_summary.csv", row.names = FALSE)
# write.csv(missing_analysis, "output/data_exploration/missing_values_detail.csv", row.names = FALSE)
# write.csv(outlier_analysis, "output/data_exploration/outliers_detail.csv", row.names = FALSE)
# write.csv(neighbors_analysis, "output/data_exploration/spatial_connectivity.csv", row.names = FALSE)

# === 10. ë°ì´í„° ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸ ===
# 
# # ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸
# checklist <- data.frame(
#   Check_Item = c(
#     "Data Downloaded", "Data Preprocessed", "Spatial Structure Valid",
#     "Missing Values Handled", "Outliers Identified", "Numeric Variables Ready",
#     "Spatial Weights Matrix Created", "MPSA Compatible", "PCA Compatible",
#     "Moran's I Compatible", "LIMSA Compatible", "Lee2012 Compatible"
#   ),
#   Status = c(
#     ifelse(file.exists("data/franklin.rds"), "âœ… Pass", "âŒ Fail"),
#     ifelse(nrow(franklin) > 0, "âœ… Pass", "âŒ Fail"),
#     ifelse(W_properties$row_sums_check, "âœ… Pass", "âŒ Fail"),
#     ifelse(data_report$data_quality$total_missing == 0, "âœ… Pass", "âš ï¸ Check"),
#     ifelse(data_report$data_quality$total_outliers < nrow(franklin) * 0.1, "âœ… Pass", "âš ï¸ Check"),
#     ifelse(ncol(numeric_data) >= 3, "âœ… Pass", "âŒ Fail"),
#     ifelse(exists("W_matrix"), "âœ… Pass", "âŒ Fail"),
#     "âœ… Pass", "âœ… Pass", "âœ… Pass", "âœ… Pass", "âœ… Pass"
#   ),
#   Notes = c(
#     "Franklin County data saved to data/franklin.rds",
#     paste(nrow(franklin), "census tracts loaded"),
#     "Row-normalized spatial weights matrix",
#     paste(data_report$data_quality$total_missing, "missing values total"),
#     paste(data_report$data_quality$total_outliers, "outliers detected"),
#     paste(ncol(numeric_data), "numeric variables available"),
#     paste(W_properties$total_connections, "spatial connections"),
#     "Ready for Random Forest proximity calculation",
#     "Ready for PCA dimension reduction",
#     "Ready for univariate spatial autocorrelation",
#     "Ready for multivariate LISA analysis",
#     "Ready for Mahalanobis distance calculation"
#   )
# )
# 
# # ì²´í¬ë¦¬ìŠ¤íŠ¸ ì €ì¥
# write.csv(checklist, "output/data_exploration/data_preparation_checklist.csv", row.names = FALSE)
# 
# # ìµœì¢… ìš”ì•½ ì¶œë ¥
# cat("=== ë°ì´í„° ì¤€ë¹„ ë° ê²€ì¦ ì™„ë£Œ ===\n")
# cat("ğŸ“Š ë°ì´í„° ê°œìš”:\n")
# cat(sprintf("  - ì—°êµ¬ ì§€ì—­: %s\n", data_report$study_area))
# cat(sprintf("  - Census Tracts: %dê°œ\n", data_report$n_census_tracts))
# cat(sprintf("  - ìˆ˜ì¹˜í˜• ë³€ìˆ˜: %dê°œ\n", data_report$n_variables))
# cat("ğŸ” ë°ì´í„° í’ˆì§ˆ:\n")
# cat(sprintf("  - ê²°ì¸¡ê°’: %dê°œ\n", data_report$data_quality$total_missing))
# cat(sprintf("  - ì´ìƒê°’: %dê°œ\n", data_report$data_quality$total_outliers))
# cat("ğŸ—ºï¸  ê³µê°„ íŠ¹ì„±:\n")
# cat(sprintf("  - í‰ê·  ì´ì›ƒ ìˆ˜: %.2fê°œ\n", data_report$spatial_properties$average_neighbors))
# cat(sprintf("  - ì´ ê³µê°„ ì—°ê²°: %dê°œ\n", data_report$spatial_properties$total_connections))
# cat("âœ… ë°©ë²•ë¡  í˜¸í™˜ì„±:\n")
# for (i in 1:nrow(compatibility_test)) {
#   cat(sprintf("  - %s: %s\n", compatibility_test$Method[i], compatibility_test$Compatible[i]))
# }
# cat("ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: output/data_exploration/\n")
# cat("ğŸ¯ ëª¨ë“  ë¶„ì„ ë°©ë²•ë¡  ì‚¬ìš© ì¤€ë¹„ ì™„ë£Œ!\n")

# === 7. ê¸°ë³¸ ì‹œê°í™” ë° ì§€ë„ ìƒì„± =======================================

# ê¸°ë³¸ ì§€ë„ (tmap 4.1 ë²„ì „)
# base_map <- tm_shape(franklin) +
#   tm_borders(col = "gray", alpha = 0.7) +
#   tm_layout(
#     title = "Franklin County Census Tracts",
#     title.position = c("center", "top")
#   )

# ë³€ìˆ˜ë³„ ì§€ë„ ìƒì„± í•¨ìˆ˜ (tmap 4.1 ë²„ì „)
# create_variable_maps <- function(data, variables) {
#   maps <- list()
#   for (var in variables) {
#     spatial_map <- tm_shape(franklin) +
#       tm_fill(
#         fill = var,
#         fill.scale = tm_scale_continuous(
#           palette = "viridis"
#         ),
#         fill.legend = tm_legend(title = var)
#       ) +
#       tm_borders(alpha = 0.3, col = "white") +
#       tm_layout(
#         title = paste("Distribution of", var),
#         title.position = c("center", "top")
#       )
#     
#     tmap_save(spatial_map,
#               filename = paste0("output/eda/", var, "_map.png"),
#               width = 8, height = 6, dpi = 300)
#     maps[[var]] <- spatial_map
#   }
#   return(maps)
# }

# === íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ë¡œë”© í•¨ìˆ˜ ===
install_and_load <- function(packages) {
  for (pkg in packages) {
    if (!require(pkg, character.only = TRUE)) {
      cat("ğŸ“¦ Installing package:", pkg, "\n")
      install.packages(pkg, dependencies = TRUE)
      library(pkg, character.only = TRUE)
    }
  }
}

# === íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ë¡œë”© ì‹¤í–‰ ===
install_and_load(required_packages)

# ğŸ†• tmap 4.1 ë²„ì „ í™•ì¸ ë° ì„¤ì •
if (packageVersion("tmap") >= "4.0") {
  cat("âœ… tmap 4.x ë²„ì „ í™•ì¸ë¨ - ìƒˆë¡œìš´ ë¬¸ë²• ì‚¬ìš©\n")
  # tmap 4.xì˜ ê¸°ë³¸ ì„¤ì •
  tmap_options(check.and.fix = TRUE)
} else {
  cat("âš ï¸  tmap 3.x ë²„ì „ - ì—…ê·¸ë ˆì´ë“œ ê¶Œì¥\n")
  cat("   install.packages('tmap') ì‹¤í–‰í•˜ì—¬ ìµœì‹  ë²„ì „ ì„¤ì¹˜\n")
}