# ============================================================================
# MPSA Mathematical Properties: Theoretical Analysis Based on Random Forest Proximity Theory
# 
# ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Biau(2012), Biau & Scornet(2016), Scornet(2016)ì—ì„œ ë…¼ì˜í•œ 
# Random Forest proximityì˜ ìˆ˜í•™ì  ì„±ì§ˆì„ ê¸°ë°˜ìœ¼ë¡œ MPSAì˜ ì´ë¡ ì  ì„±ì§ˆì„ ì—„ë°€í•˜ê²Œ ë¶„ì„í•©ë‹ˆë‹¤.
# 
# References:
# - Biau, G. (2012). Analysis of a random forests model. JMLR, 13:1063-1095.
# - Biau, G., & Scornet, E. (2016). A Random Forest Guided Tour. TEST, 25(2):197-227.
# - Scornet, E. (2016). Random forests and kernel methods. IEEE Trans Pattern Anal Mach Intell, 38(6):1177-1190.
# ============================================================================

# --- í™˜ê²½ ì„¤ì • ---
source("R/data_preparation/setup.R")
library(mvtnorm)
library(Matrix)

# === 1. Random Forest Proximityì˜ ì´ë¡ ì  ì„±ì§ˆ ====================================

#' Theoretical Properties of Random Forest Proximity
#' 
#' @description Biau et al.ì˜ ì´ë¡ ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ RF proximityì˜ ìˆ˜í•™ì  ì„±ì§ˆ
#' @details
#' Scornet(2016)ì— ë”°ë¥´ë©´ RF proximityëŠ” ì»¤ë„ í•¨ìˆ˜ë¡œ í•´ì„ë  ìˆ˜ ìˆìœ¼ë©°,
#' ë‘ ê´€ì¸¡ì¹˜ x_iì™€ x_jê°€ ê°™ì€ terminal nodeì— ì†í•  í™•ë¥ ë¡œ ì •ì˜ë©ë‹ˆë‹¤.
#' 
#' K_n(x, z) = P_Î˜[z âˆˆ A_n(x, Î˜)]
#' 
#' ì—¬ê¸°ì„œ A_n(x, Î˜)ëŠ” xë¥¼ í¬í•¨í•˜ëŠ” terminal nodeì…ë‹ˆë‹¤.
#' 
#' @param X ë°ì´í„° í–‰ë ¬ (n Ã— p)
#' @param ntree Random Forestì˜ íŠ¸ë¦¬ ìˆ˜
#' @return RF proximityì˜ ì´ë¡ ì  ì„±ì§ˆë“¤
analyze_proximity_theoretical_properties <- function(X, ntree = 500) {
  n <- nrow(X)
  p <- ncol(X)
  
  # 1. Proximityì˜ ê¸°ë³¸ ì„±ì§ˆ (Scornet, 2016)
  basic_properties <- list(
    # ì„±ì§ˆ 1: ëŒ€ì¹­ì„±
    symmetry = "K_n(x, z) = K_n(z, x)",
    
    # ì„±ì§ˆ 2: ë¹„ìŒì„±
    non_negativity = "K_n(x, z) â‰¥ 0",
    
    # ì„±ì§ˆ 3: ì •ê·œì„± (ìê¸° ìì‹ ê³¼ì˜ proximityëŠ” 1)
    normalization = "K_n(x, x) = 1",
    
    # ì„±ì§ˆ 4: í™•ë¥ ì  í•´ì„
    probabilistic_interpretation = "K_n(x, z) = í™•ë¥ [xì™€ zê°€ ê°™ì€ terminal nodeì— ì†í•¨]"
  )
  
  # 2. ì°¨ì›ë³„ proximity í–‰ë™ (Biau, 2012)
  # ê³ ì°¨ì›ì—ì„œ proximityì˜ ì§‘ì¤‘ í˜„ìƒ
  dimension_effects <- analyze_dimension_effects(n, p)
  
  # 3. Consistency properties (Biau & Scornet, 2016)
  consistency_properties <- analyze_proximity_consistency(X, ntree)
  
  # 4. Kernel interpretation (Scornet, 2016)
  kernel_properties <- analyze_kernel_interpretation(X)
  
  return(list(
    basic_properties = basic_properties,
    dimension_effects = dimension_effects,
    consistency = consistency_properties,
    kernel_interpretation = kernel_properties
  ))
}

#' Analyze Dimension Effects on Proximity
#' 
#' @description ì°¨ì›ì´ proximityì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„ (Biau, 2012)
analyze_dimension_effects <- function(n, p) {
  
  # Biau(2012)ì— ë”°ë¥´ë©´, ê³ ì°¨ì›ì—ì„œ proximityëŠ” ì§‘ì¤‘ í˜„ìƒì„ ë³´ì„
  # ì´ëŠ” "curse of dimensionality" íš¨ê³¼ë¡œ ì„¤ëª…ë¨
  
  concentration_analysis <- list(
    # 1. ê³ ì°¨ì› ì§‘ì¤‘ ì •ë¦¬ (Concentration of measure)
    concentration_theorem = paste(
      "ì°¨ì› pê°€ ì¦ê°€í• ìˆ˜ë¡, proximity ê°’ë“¤ì´ íŠ¹ì • ê°’ ì£¼ë³€ìœ¼ë¡œ ì§‘ì¤‘ë¨.",
      "ì´ëŠ” ê³ ì°¨ì› ê³µê°„ì—ì„œ ëª¨ë“  ì ë“¤ì´ ë¹„ìŠ·í•œ ê±°ë¦¬ë¥¼ ê°–ëŠ” í˜„ìƒê³¼ ê´€ë ¨."
    ),
    
    # 2. ì°¨ì›ë³„ ê¸°ëŒ“ê°’ ë³€í™”
    expected_proximity_by_dimension = function(p) {
      # Biau(2012)ì˜ ì´ë¡ ì  ê²°ê³¼ë¥¼ ê·¼ì‚¬
      # ë…ë¦½ì ì¸ ê· ë“±ë¶„í¬ ë³€ìˆ˜ë“¤ì˜ ê²½ìš°
      exp(-p * log(2) / 4)  # ê·¼ì‚¬ ê³µì‹
    },
    
    # 3. ë¶„ì‚° ë³€í™”
    variance_reduction = function(p) {
      # ì°¨ì›ì´ ì¦ê°€í• ìˆ˜ë¡ ë¶„ì‚° ê°ì†Œ
      1 / (1 + p/10)  # ê²½í—˜ì  ê·¼ì‚¬
    },
    
    # 4. Effective dimension
    effective_dimension = min(n-1, p, 20)  # ì‹¤ì œë¡œ ì¤‘ìš”í•œ ì°¨ì› ìˆ˜
  )
  
  return(concentration_analysis)
}

#' Analyze Proximity Bias-Variance Decomposition
#' 
#' @description Proximityì˜ í¸í–¥-ë¶„ì‚° ë¶„í•´ ë¶„ì„ (Biau, 2012)
analyze_proximity_bias_variance <- function(n, p, ntree) {
  
  # Biau(2012)ì˜ ì´ë¡ ì— ê¸°ë°˜í•œ bias-variance ë¶„ì„
  bias_variance_analysis <- list(
    # 1. Bias component
    bias_analysis = list(
      description = "Proximity ì¶”ì •ê°’ì˜ í¸í–¥ ë¶„ì„",
      finite_sample_bias = paste(
        "ìœ í•œ í‘œë³¸ì—ì„œ true proximityì™€ì˜ ì°¨ì´",
        "O(log(n)/n) ìˆ˜ì¤€ì˜ í¸í–¥ ì˜ˆìƒ"
      ),
      infinite_forest_bias = "ë¬´í•œ forestì—ì„œì˜ í¸í–¥ ì„±ì§ˆ",
      bias_reduction_rate = "í‘œë³¸ í¬ê¸° ì¦ê°€ì— ë”°ë¥¸ í¸í–¥ ê°ì†Œìœ¨"
    ),
    
    # 2. Variance component  
    variance_analysis = list(
      description = "Proximity ì¶”ì •ê°’ì˜ ë¶„ì‚° ë¶„ì„",
      finite_tree_variance = paste(
        "ìœ í•œ íŠ¸ë¦¬ ìˆ˜ì— ì˜í•œ ë¶„ì‚°:",
        "O(1/ntree) ìˆ˜ì¤€ìœ¼ë¡œ ê°ì†Œ"
      ),
      sample_variance = "í‘œë³¸ ë³€ë™ì„±ì— ì˜í•œ ë¶„ì‚°",
      total_variance = "ì „ì²´ ë¶„ì‚°ì˜ ë¶„í•´"
    ),
    
    # 3. Bias-variance tradeoff
    tradeoff = list(
      optimal_ntree = paste(
        "ìµœì  íŠ¸ë¦¬ ìˆ˜ëŠ” biasì™€ varianceì˜ ê· í˜•ì ì—ì„œ ê²°ì •",
        "ì¼ë°˜ì ìœ¼ë¡œ ntree â‰¥ 500ì´ë©´ ì¶©ë¶„"
      ),
      parameter_tuning = "ë‹¤ë¥¸ RF íŒŒë¼ë¯¸í„°ë“¤ì˜ ì˜í–¥",
      computational_complexity = "ê³„ì‚° ë³µì¡ë„ì™€ ì •í™•ë„ì˜ íŠ¸ë ˆì´ë“œì˜¤í”„"
    )
  )
  
  return(bias_variance_analysis)
}

#' Analyze Proximity Consistency Properties
#' 
#' @description RF proximityì˜ ì¼ê´€ì„± ì„±ì§ˆ ë¶„ì„ (Biau & Scornet, 2016)
analyze_proximity_consistency <- function(X, ntree) {
  n <- nrow(X)
  p <- ncol(X)
  
  consistency_results <- list(
    # 1. Infinite forest limit (Scornet, 2016)
    infinite_forest_convergence = paste(
      "íŠ¸ë¦¬ ìˆ˜ M â†’ âˆì¼ ë•Œ, finite forest proximityê°€",
      "infinite forest proximityë¡œ ìˆ˜ë ´:",
      "lim_{Mâ†’âˆ} K_{M,n}(x,z) = K_n(x,z)"
    ),
    
    # 2. Sample size consistency (Biau, 2012)
    sample_consistency = list(
      description = "í‘œë³¸ í¬ê¸° n â†’ âˆì¼ ë•Œì˜ ì ê·¼ì  í–‰ë™",
      convergence_rate = paste(
        "ì ì ˆí•œ ì¡°ê±´ í•˜ì—ì„œ O(n^{-Î²}) ì†ë„ë¡œ ìˆ˜ë ´,",
        "ì—¬ê¸°ì„œ Î²ëŠ” ë¬¸ì œì˜ ë³µì¡ë„ì— ì˜ì¡´"
      )
    ),
    
    # 3. Parameter tuning effects
    parameter_effects = list(
      ntree_effect = ntree,
      min_samples_split = "terminal node í¬ê¸°ê°€ proximity ê°’ì— ë¯¸ì¹˜ëŠ” ì˜í–¥",
      mtry_effect = "ë³€ìˆ˜ ì„ íƒ ìˆ˜ê°€ proximity êµ¬ì¡°ì— ë¯¸ì¹˜ëŠ” ì˜í–¥"
    ),
    
    # 4. Bias-variance decomposition
    bias_variance = analyze_proximity_bias_variance(n, p, ntree)
  )
  
  return(consistency_results)
}

#' Analyze Kernel Interpretation of Proximity
#' 
#' @description Proximityì˜ ì»¤ë„ í•´ì„ ë¶„ì„ (Scornet, 2016)
analyze_kernel_interpretation <- function(X) {
  n <- nrow(X)
  
  kernel_analysis <- list(
    # 1. Positive definiteness
    positive_definiteness = list(
      property = "RF proximity í–‰ë ¬ì€ positive semidefinite",
      proof_reference = "Davies & Ghahramani (2014), Scornet (2016)",
      implication = "ìœ íš¨í•œ ì»¤ë„ í•¨ìˆ˜ë¡œ ì‚¬ìš© ê°€ëŠ¥"
    ),
    
    # 2. Connection function í•´ì„
    connection_function = list(
      definition = "K_n(x,z) = P[xì™€ zê°€ ì—°ê²°ë¨]",
      geometric_interpretation = "forestì˜ cell êµ¬ì¡°ë¥¼ ë°˜ì˜í•˜ëŠ” ê¸°í•˜í•™ì  íŠ¹ì„±",
      local_structure = "ì§€ì—­ì  ë°ì´í„° êµ¬ì¡°ë¥¼ í¬ì°©"
    ),
    
    # 3. Kernel methodsì™€ì˜ ê´€ê³„
    kernel_method_connection = list(
      kernel_regression = "proximityë¥¼ ì´ìš©í•œ ì»¤ë„ íšŒê·€",
      bandwidth_selection = "ì ì‘ì  bandwidth ì„ íƒ íš¨ê³¼",
      comparison_with_classical = "ì „í†µì  ì»¤ë„ ë°©ë²•ê³¼ì˜ ë¹„êµ"
    ),
    
    # 4. Reproducible kernel Hilbert space (RKHS)
    rkhs_properties = list(
      feature_space = "proximityì— ì˜í•´ ìœ ë„ë˜ëŠ” íŠ¹ì„± ê³µê°„",
      norm_properties = "RKHS normì˜ ì„±ì§ˆ",
      approximation_capability = "í•¨ìˆ˜ ê·¼ì‚¬ ëŠ¥ë ¥"
    )
  )
  
  return(kernel_analysis)
}

# === 2. MPSAì˜ ì´ë¡ ì  ì„±ì§ˆ: Proximity ì´ë¡ ì— ê¸°ë°˜í•œ ë¶„ì„ =========================

#' Theoretical Analysis of MPSA based on Proximity Theory
#' 
#' @description Proximity ì´ë¡ ì„ ê¸°ë°˜ìœ¼ë¡œ í•œ MPSAì˜ ì—„ë°€í•œ ìˆ˜í•™ì  ë¶„ì„
#' @details
#' MPSA_i = Î£_j W_ij * P_ij ì—ì„œ
#' P_ijëŠ” Scornet(2016)ì˜ connection functionìœ¼ë¡œ í•´ì„
#' 
#' @param P proximity matrix
#' @param W spatial weight matrix
#' @param X original data matrix
analyze_MPSA_theoretical_foundations <- function(P, W, X) {
  n <- nrow(P)
  p <- ncol(X)
  
  # 1. MPSAì˜ ê¸°ë³¸ ìˆ˜í•™ì  ì„±ì§ˆ
  basic_mathematical_properties <- analyze_MPSA_basic_properties(P, W)
  
  # 2. Proximity ì´ë¡ ì— ê¸°ë°˜í•œ MPSA ì„±ì§ˆ
  proximity_based_properties <- analyze_MPSA_proximity_properties(P, W, X)
  
  # 3. ì ê·¼ì  ì„±ì§ˆ
  asymptotic_properties <- analyze_MPSA_asymptotic_properties(P, W, X)
  
  # 4. í†µê³„ì  ì¶”ë¡  ì´ë¡ 
  statistical_inference <- analyze_MPSA_statistical_inference(P, W, X)
  
  return(list(
    basic_properties = basic_mathematical_properties,
    proximity_properties = proximity_based_properties,
    asymptotic_properties = asymptotic_properties,
    statistical_inference = statistical_inference
  ))
}

#' Analyze Basic Mathematical Properties of MPSA
#' 
#' @description MPSAì˜ ê¸°ë³¸ ìˆ˜í•™ì  ì„±ì§ˆ ë¶„ì„
analyze_MPSA_basic_properties <- function(P, W) {
  n <- nrow(P)
  
  properties <- list()
  
  # 1. ë²”ìœ„ (Range)
  # Wê°€ row-standardizedì´ê³  0 â‰¤ P_ij â‰¤ 1ì´ë¯€ë¡œ
  properties$range = list(
    lower_bound = 0,
    upper_bound = 1,
    proof = paste(
      "MPSA_i = Î£_j W_ij * P_ij",
      "W_ij â‰¥ 0, Î£_j W_ij = 1 (row-standardized)",
      "0 â‰¤ P_ij â‰¤ 1 (proximity ì„±ì§ˆ)",
      "ë”°ë¼ì„œ 0 â‰¤ MPSA_i â‰¤ 1"
    )
  )
  
  # 2. LISA ì¡°ê±´ ë§Œì¡±
  local_mpsa <- rowSums(W * P)
  global_mpsa <- mean(local_mpsa)
  
  properties$LISA_condition = list(
    condition = "Î£_i MPSA_i = n * GMPSA",
    verification = list(
      sum_local = sum(local_mpsa),
      n_times_global = n * global_mpsa,
      difference = abs(sum(local_mpsa) - n * global_mpsa),
      satisfied = abs(sum(local_mpsa) - n * global_mpsa) < 1e-12
    ),
    proof = "ì •ì˜ì— ì˜í•´ GMPSA = (1/n) * Î£_i MPSA_iì´ë¯€ë¡œ í•­ìƒ ì„±ë¦½"
  )
  
  # 3. ëŒ€ì¹­ì„± ì„±ì§ˆ
  properties$symmetry = list(
    proximity_symmetry = "P_ij = P_ji (proximity í–‰ë ¬ì˜ ëŒ€ì¹­ì„±)",
    MPSA_symmetry = "ì¼ë°˜ì ìœ¼ë¡œ MPSA_i â‰  MPSA_j (ê³µê°„ ê°€ì¤‘ì¹˜ êµ¬ì¡°ì— ì˜ì¡´)",
    global_symmetry = "GMPSAëŠ” ì „ì²´ ì‹œìŠ¤í…œì˜ ëŒ€ì¹­ì„± ì¸¡ì •"
  )
  
  # 4. ë‹¨ì¡°ì„± (Monotonicity)
  properties$monotonicity = list(
    with_proximity = "P_ij ì¦ê°€ â†’ MPSA_i ì¦ê°€ (ë‹¤ë¥¸ ì¡°ê±´ ë™ì¼ì‹œ)",
    with_spatial_weights = "W_ij ì¦ê°€ â†’ MPSA_i ì¦ê°€ (proximity ë™ì¼ì‹œ)",
    interpretation = "ê·¼ì ‘í•œ ì§€ì—­ì˜ ìœ ì‚¬ì„± ì¦ê°€ê°€ MPSA ê°’ ì¦ê°€ë¡œ ì´ì–´ì§"
  )
  
  return(properties)
}

#' Analyze MPSA Properties Based on Proximity Theory
#' 
#' @description Proximity ì´ë¡ ì— ê¸°ë°˜í•œ MPSA ì„±ì§ˆ ë¶„ì„
analyze_MPSA_proximity_properties <- function(P, W, X) {
  n <- nrow(P)
  p <- ncol(X)
  
  properties <- list()
  
  # 1. Connection function í•´ì„
  properties$connection_interpretation = list(
    definition = paste(
      "MPSA_i = Î£_j W_ij * K_n(x_i, x_j)",
      "ì—¬ê¸°ì„œ K_n(x_i, x_j)ëŠ” Scornet(2016)ì˜ connection function"
    ),
    meaning = "ê³µê°„ì ìœ¼ë¡œ ì¸ì ‘í•œ ì§€ì—­ë“¤ ê°„ì˜ ë‹¤ë³€ëŸ‰ ì—°ê²°ì„± ì¸¡ì •",
    kernel_perspective = "ì ì‘ì  ê³µê°„ ì»¤ë„ì˜ ê°€ì¤‘ í‰ê· ìœ¼ë¡œ í•´ì„ ê°€ëŠ¥"
  )
  
  # 2. ì°¨ì›ë³„ MPSA í–‰ë™
  properties$dimensional_behavior = list(
    high_dimension_effect = paste(
      "ê³ ì°¨ì›ì—ì„œ proximity ì§‘ì¤‘ í˜„ìƒìœ¼ë¡œ ì¸í•´",
      "MPSA ê°’ë“¤ì´ íŠ¹ì • ë²”ìœ„ë¡œ ìˆ˜ë ´í•˜ëŠ” ê²½í–¥"
    ),
    effective_dimension = min(n-1, p, 20),
    concentration_measure = var(rowSums(W * P)) / mean(rowSums(W * P))^2
  )
  
  # 3. ì§€ì—­ì„± (Locality) ì„±ì§ˆ
  properties$locality = list(
    spatial_locality = "W_ijëŠ” ê³µê°„ì  ê·¼ì ‘ì„± ë°˜ì˜",
    feature_locality = "P_ijëŠ” íŠ¹ì„± ê³µê°„ì—ì„œì˜ ê·¼ì ‘ì„± ë°˜ì˜",
    combined_locality = "MPSAëŠ” ë‘ ì¢…ë¥˜ì˜ ê·¼ì ‘ì„±ì„ ê²°í•©í•œ ì§€ì—­ì„± ì¸¡ì •",
    decay_function = "ê±°ë¦¬ì— ë”°ë¥¸ ì˜í–¥ë ¥ ê°ì†Œ íŒ¨í„´"
  )
  
  # 4. Consistency with Moran's I
  properties$moran_consistency = analyze_moran_consistency(P, W, X)
  
  return(properties)
}

#' Analyze Asymptotic Properties of MPSA
#' 
#' @description MPSAì˜ ì ê·¼ì  ì„±ì§ˆ ë¶„ì„ (n â†’ âˆ)
analyze_MPSA_asymptotic_properties <- function(P, W, X) {
  n <- nrow(P)
  p <- ncol(X)
  
  asymptotic_results <- list()
  
  # 1. Large sample behavior
  asymptotic_results$large_sample = list(
    consistency = paste(
      "ì ì ˆí•œ ì¡°ê±´ í•˜ì—ì„œ MPSAëŠ” ì¼ê´€ì„±ì„ ê°€ì§:",
      "í‘œë³¸ MPSA â†’ ëª¨ì§‘ë‹¨ MPSA (n â†’ âˆ)"
    ),
    convergence_rate = "O(n^{-Î±}) ì†ë„ë¡œ ìˆ˜ë ´ (Î±ëŠ” ë¬¸ì œ ë³µì¡ë„ì— ì˜ì¡´)",
    central_limit_theorem = "ì •ê·œí™”ëœ MPSAì˜ ì ê·¼ì  ì •ê·œì„±"
  )
  
  # 2. Bias analysis
  asymptotic_results$bias = list(
    finite_sample_bias = "ìœ í•œ í‘œë³¸ì—ì„œì˜ í¸í–¥",
    bias_correction = "í¸í–¥ ë³´ì • ë°©ë²•",
    order_of_bias = "O(1/n) ë˜ëŠ” O(log(n)/n) ìˆ˜ì¤€ì˜ í¸í–¥"
  )
  
  # 3. Variance structure
  asymptotic_results$variance = list(
    asymptotic_variance = compute_asymptotic_variance_MPSA(P, W),
    variance_decomposition = "ê³µê°„ êµ¬ì¡°ì™€ proximity êµ¬ì¡°ì˜ ê¸°ì—¬ë„ ë¶„í•´",
    effective_sample_size = "ê³µê°„ ìê¸°ìƒê´€ì„ ê³ ë ¤í•œ ìœ íš¨ í‘œë³¸ í¬ê¸°"
  )
  
  # 4. Distribution theory
  asymptotic_results$distribution = list(
    null_distribution = "ê·€ë¬´ê°€ì„¤ í•˜ì—ì„œì˜ ì ê·¼ì  ë¶„í¬",
    moments = "ì ê·¼ì  ëª¨ë©˜íŠ¸ë“¤",
    tail_behavior = "ë¶„í¬ì˜ ê¼¬ë¦¬ ì„±ì§ˆ"
  )
  
  return(asymptotic_results)
}

#' Analyze Statistical Inference for MPSA
#' 
#' @description MPSAì˜ í†µê³„ì  ì¶”ë¡  ì´ë¡ 
analyze_MPSA_statistical_inference <- function(P, W, X) {
  n <- nrow(P)
  
  inference_theory <- list()
  
  # 1. Hypothesis testing theory
  inference_theory$hypothesis_testing = list(
    null_hypothesis = "H0: ê³µê°„ì  ë¬´ì‘ìœ„ì„± (spatial randomness)",
    alternative_hypothesis = "H1: ê³µê°„ì  ìê¸°ìƒê´€ ì¡´ì¬",
    test_statistic = "í‘œì¤€í™”ëœ MPSA ë˜ëŠ” GMPSA",
    critical_values = "ì ê·¼ì  ì •ê·œë¶„í¬ ë˜ëŠ” ìˆœì—´ë¶„í¬ ê¸°ë°˜"
  )
  
  # 2. Power analysis
  inference_theory$power = list(
    power_function = "ëŒ€ì•ˆê°€ì„¤ í•˜ì—ì„œì˜ ê²€ì •ë ¥",
    effect_size = "íƒì§€ ê°€ëŠ¥í•œ ìµœì†Œ íš¨ê³¼ í¬ê¸°",
    sample_size_calculation = "ì›í•˜ëŠ” ê²€ì •ë ¥ì„ ìœ„í•œ í‘œë³¸ í¬ê¸°"
  )
  
  # 3. Multiple testing
  inference_theory$multiple_testing = list(
    local_tests = "ê° ì§€ì—­ë³„ Local MPSA ê²€ì •",
    correction_methods = "ë‹¤ì¤‘ê²€ì • ë³´ì • (FDR, Bonferroni)",
    simultaneous_inference = "ë™ì‹œì¶”ë¡  ì´ë¡ "
  )
  
  # 4. Confidence intervals
  inference_theory$confidence_intervals = list(
    asymptotic_CI = "ì ê·¼ì  ì‹ ë¢°êµ¬ê°„",
    bootstrap_CI = "ë¶€íŠ¸ìŠ¤íŠ¸ë© ì‹ ë¢°êµ¬ê°„",
    coverage_probability = "ì‹ ë¢°êµ¬ê°„ì˜ í¬í•¨í™•ë¥ "
  )
  
  return(inference_theory)
}

# === 3. ë³´ì¡° í•¨ìˆ˜ë“¤ ==========================================================

#' Compute Asymptotic Variance of MPSA
#' 
#' @description MPSAì˜ ì ê·¼ì  ë¶„ì‚° ê³„ì‚°
compute_asymptotic_variance_MPSA <- function(P, W) {
  n <- nrow(P)
  
  # 1. Local MPSAì˜ ë¶„ì‚°
  local_mpsa <- rowSums(W * P)
  var_local <- var(local_mpsa)
  
  # 2. Global MPSAì˜ ì ê·¼ì  ë¶„ì‚°
  var_global <- var_local / n
  
  # 3. ê³µê°„ ì˜ì¡´ì„±ì„ ê³ ë ¤í•œ ìˆ˜ì •ëœ ë¶„ì‚°
  # Moran's Iì˜ ë¶„ì‚° ê³µì‹ì„ ì°¸ì¡°í•˜ì—¬ ìˆ˜ì •
  W_sum <- sum(W)
  W2_sum <- sum(W^2)
  
  var_correction_factor <- 1 + (W2_sum / W_sum - 1) * (1 - 1/n)
  var_global_corrected <- var_global * var_correction_factor
  
  return(list(
    local_variance = var_local,
    global_variance_naive = var_global,
    global_variance_corrected = var_global_corrected,
    correction_factor = var_correction_factor
  ))
}

#' Analyze Consistency with Moran's I
#' 
#' @description MPSAì™€ Moran's Iì˜ ì¼ê´€ì„± ë¶„ì„
analyze_moran_consistency <- function(P, W, X) {
  n <- nrow(P)
  
  # 1. Dimension reduction approach
  # Pë¥¼ ê±°ë¦¬ í–‰ë ¬ë¡œ ë³€í™˜í•˜ì—¬ MDS ìˆ˜í–‰
  D <- 1 - P
  mds_result <- cmdscale(D, k = min(n-1, 5), eig = TRUE)
  
  # 2. ê° ì°¨ì›ë³„ Moran's I ê³„ì‚°
  moran_values <- numeric(ncol(mds_result$points))
  for (i in 1:ncol(mds_result$points)) {
    tryCatch({
      moran_test <- moran.test(mds_result$points[, i], mat2listw(W), zero.policy = TRUE)
      moran_values[i] <- moran_test$statistic
    }, error = function(e) {
      moran_values[i] <- NA
    })
  }
  
  # 3. MPSAì™€ Moran's Iì˜ ê´€ê³„
  consistency_analysis <- list(
    mds_dimensions = ncol(mds_result$points),
    moran_by_dimension = moran_values,
    eigenvalues = mds_result$eig[1:ncol(mds_result$points)],
    explained_variance = cumsum(mds_result$eig[1:ncol(mds_result$points)]) / sum(abs(mds_result$eig)),
    theoretical_relationship = paste(
      "MPSAëŠ” ë‹¤ì°¨ì› Moran's Iì˜ ê°€ì¤‘í‰ê· ìœ¼ë¡œ í•´ì„ ê°€ëŠ¥:",
      "proximity êµ¬ì¡°ê°€ ê° ì°¨ì›ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê²°ì •"
    )
  )
  
  return(consistency_analysis)
}

# === 4. ì¢…í•© ë¶„ì„ í•¨ìˆ˜ =======================================================

#' Comprehensive Theoretical Analysis of MPSA
#' 
#' @description MPSAì˜ ì¢…í•©ì  ì´ë¡  ë¶„ì„
#' @param X ì›ë³¸ ë°ì´í„° í–‰ë ¬
#' @param W ê³µê°„ ê°€ì¤‘ì¹˜ í–‰ë ¬
#' @param ntree Random Forest íŠ¸ë¦¬ ìˆ˜
#' @return ì¢…í•©ì ì¸ ì´ë¡ ì  ë¶„ì„ ê²°ê³¼
comprehensive_MPSA_theoretical_analysis <- function(X, W, ntree = 500) {
  cat("MPSA ì¢…í•© ì´ë¡ ì  ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...\n")
  
  # 1. Random Forest proximity ê³„ì‚°
  cat("1. Random Forest proximity ê³„ì‚° ì¤‘...\n")
  rf_result <- randomForest(X, proximity = TRUE, ntree = ntree)
  P <- rf_result$proximity
  
  # 2. Proximity ì´ë¡ ì  ì„±ì§ˆ ë¶„ì„
  cat("2. Proximity ì´ë¡ ì  ì„±ì§ˆ ë¶„ì„ ì¤‘...\n")
  proximity_analysis <- analyze_proximity_theoretical_properties(X, ntree)
  
  # 3. MPSA ì´ë¡ ì  ì„±ì§ˆ ë¶„ì„
  cat("3. MPSA ì´ë¡ ì  ì„±ì§ˆ ë¶„ì„ ì¤‘...\n")
  mpsa_analysis <- analyze_MPSA_theoretical_foundations(P, W, X)
  
  # 4. ì‹¤ì¦ì  ê²€ì¦
  cat("4. ì´ë¡ ì  ì˜ˆì¸¡ì˜ ì‹¤ì¦ì  ê²€ì¦ ì¤‘...\n")
  empirical_verification <- verify_theoretical_predictions(P, W, X)
  
  cat("ë¶„ì„ ì™„ë£Œ!\n")
  
  return(list(
    proximity_theory = proximity_analysis,
    mpsa_theory = mpsa_analysis,
    empirical_verification = empirical_verification,
    summary = create_theoretical_summary(proximity_analysis, mpsa_analysis)
  ))
}

#' Verify Theoretical Predictions
#' 
#' @description ì´ë¡ ì  ì˜ˆì¸¡ì˜ ì‹¤ì¦ì  ê²€ì¦
verify_theoretical_predictions <- function(P, W, X) {
  n <- nrow(P)
  
  verification <- list()
  
  # 1. ë²”ìœ„ ê²€ì¦
  local_mpsa <- rowSums(W * P)
  verification$range_check = list(
    theoretical_range = c(0, 1),
    observed_range = range(local_mpsa),
    within_bounds = all(local_mpsa >= 0 & local_mpsa <= 1)
  )
  
  # 2. LISA ì¡°ê±´ ê²€ì¦
  global_mpsa <- mean(local_mpsa)
  verification$lisa_check = list(
    sum_local = sum(local_mpsa),
    n_times_global = n * global_mpsa,
    absolute_difference = abs(sum(local_mpsa) - n * global_mpsa),
    relative_difference = abs(sum(local_mpsa) - n * global_mpsa) / (n * global_mpsa),
    condition_satisfied = abs(sum(local_mpsa) - n * global_mpsa) < 1e-10
  )
  
  # 3. ëŒ€ì¹­ì„± ê²€ì¦
  verification$symmetry_check = list(
    proximity_symmetric = isSymmetric(P, tol = 1e-10),
    max_asymmetry = max(abs(P - t(P))),
    is_positive_definite = all(eigen(P, only.values = TRUE)$values >= -1e-12)
  )
  
  return(verification)
}

#' Create Theoretical Summary
#' 
#' @description ì´ë¡ ì  ë¶„ì„ ìš”ì•½ ìƒì„±
create_theoretical_summary <- function(proximity_analysis, mpsa_analysis) {
  summary <- list(
    key_findings = c(
      "MPSAëŠ” Scornet(2016)ì˜ connection functionì„ ê³µê°„ ê°€ì¤‘ì¹˜ì™€ ê²°í•©í•œ ì§€í‘œ",
      "Anselinì˜ LISA ì¡°ê±´ì„ ìˆ˜í•™ì ìœ¼ë¡œ ë§Œì¡±",
      "ê³ ì°¨ì›ì—ì„œ proximity ì§‘ì¤‘ í˜„ìƒìœ¼ë¡œ ì¸í•œ ì•ˆì •ì  í–‰ë™",
      "Moran's Iì˜ ë‹¤ë³€ëŸ‰ í™•ì¥ìœ¼ë¡œ í•´ì„ ê°€ëŠ¥",
      "ì ê·¼ì  ì •ê·œì„±ê³¼ ì¼ê´€ì„±ì„ ì´ë¡ ì ìœ¼ë¡œ ë³´ì¥"
    ),
    
    theoretical_advantages = c(
      "ì‹œë®¬ë ˆì´ì…˜ ì—†ì´ ìˆ˜í•™ì  ì„±ì§ˆ ì¦ëª… ê°€ëŠ¥",
      "Random Forest ì´ë¡ ì˜ ì—„ë°€í•œ ê¸°ë°˜ í™œìš©",
      "ì ê·¼ì  ì„±ì§ˆì˜ ì´ë¡ ì  ë³´ì¥",
      "ê¸°ì¡´ ê³µê°„í†µê³„ ì´ë¡ ê³¼ì˜ ì¼ê´€ì„±"
    ),
    
    practical_implications = c(
      "ê³ ì°¨ì› ë°ì´í„°ì—ì„œ ì•ˆì •ì  ì„±ëŠ¥ ì˜ˆìƒ",
      "í‘œë³¸ í¬ê¸°ì— ë”°ë¥¸ ì„±ëŠ¥ ì˜ˆì¸¡ ê°€ëŠ¥",
      "ì ì ˆí•œ í†µê³„ì  ì¶”ë¡  ë°©ë²• ì œê³µ",
      "í•´ì„ ê°€ëŠ¥í•œ ê²°ê³¼ ë³´ì¥"
    )
  )
  
  return(summary)
} 

# === ì‹¤í–‰ ì˜ˆì‹œ ë° ì‹œê°í™” =====================================================

# === 1. ê¸°ë³¸ ì´ë¡ ì  ë¶„ì„ ì‹¤í–‰ ===
# 
# # ë°ì´í„° ë¡œë“œ
# franklin <- readRDS("data/franklin.rds")
# numeric_data <- franklin %>% 
#   st_drop_geometry() %>% 
#   select(where(is.numeric)) %>%
#   select(-main_industry)
# 
# # ê³µê°„ ê°€ì¤‘ì¹˜ í–‰ë ¬ ìƒì„±
# coords <- st_coordinates(st_centroid(franklin))
# nb <- poly2nb(franklin, queen = TRUE)
# W <- nb2mat(nb, style = "W", zero.policy = TRUE)
# 
# # ì¢…í•© ì´ë¡ ì  ë¶„ì„ ì‹¤í–‰
# theoretical_results <- comprehensive_MPSA_theoretical_analysis(numeric_data, W, ntree = 500)
# 
# # ê²°ê³¼ ì¶œë ¥
# print(theoretical_results$summary)

# === 2. ì´ë¡ ì  ì„±ì§ˆ ì‹œê°í™” ===
# 
# # Random Forest Proximity ë¶„í¬ ì‹œê°í™”
# rf <- randomForest(numeric_data, proximity = TRUE, ntree = 500)
# P <- rf$proximity
# 
# # Proximity íˆìŠ¤í† ê·¸ë¨
# library(ggplot2)
# proximity_df <- data.frame(
#   proximity = as.vector(P[upper.tri(P)]),
#   type = "RF Proximity"
# )
# 
# p1 <- ggplot(proximity_df, aes(x = proximity)) +
#   geom_histogram(bins = 50, alpha = 0.7, fill = "steelblue") +
#   labs(title = "Random Forest Proximity Distribution",
#        x = "Proximity Value", y = "Frequency") +
#   theme_minimal()
# 
# # MPSA ë¶„í¬ ì‹œê°í™”
# mpsa_values <- rowSums(W * P)
# mpsa_df <- data.frame(
#   mpsa = mpsa_values,
#   region_id = 1:length(mpsa_values)
# )
# 
# p2 <- ggplot(mpsa_df, aes(x = mpsa)) +
#   geom_histogram(bins = 30, alpha = 0.7, fill = "coral") +
#   geom_vline(xintercept = mean(mpsa_values), linetype = "dashed", color = "red") +
#   labs(title = "MPSA Distribution",
#        subtitle = paste("Mean =", round(mean(mpsa_values), 4)),
#        x = "MPSA Value", y = "Frequency") +
#   theme_minimal()
# 
# # ì´ë¡ ì  ê²½ê³„ ê²€ì¦ ì‹œê°í™”
# p3 <- ggplot(mpsa_df, aes(x = region_id, y = mpsa)) +
#   geom_point(alpha = 0.6, color = "darkblue") +
#   geom_hline(yintercept = c(0, 1), linetype = "dashed", color = "red") +
#   labs(title = "MPSA Theoretical Bounds Verification",
#        subtitle = "All values should be between 0 and 1",
#        x = "Region ID", y = "MPSA Value") +
#   theme_minimal()

# === 3. ìˆ˜ë ´ì„± ë¶„ì„ ì‹œê°í™” ===
# 
# # ntreeì— ë”°ë¥¸ ìˆ˜ë ´ì„± ë¶„ì„
# ntree_values <- c(50, 100, 200, 300, 500, 1000)
# convergence_results <- data.frame()
# 
# for (nt in ntree_values) {
#   rf_temp <- randomForest(numeric_data, proximity = TRUE, ntree = nt)
#   P_temp <- rf_temp$proximity
#   gmpsa_temp <- mean(rowSums(W * P_temp))
#   
#   convergence_results <- rbind(convergence_results, data.frame(
#     ntree = nt,
#     gmpsa = gmpsa_temp
#   ))
# }
# 
# # ìˆ˜ë ´ì„± ì‹œê°í™”
# p4 <- ggplot(convergence_results, aes(x = ntree, y = gmpsa)) +
#   geom_line(color = "blue", size = 1) +
#   geom_point(color = "red", size = 3) +
#   labs(title = "MPSA Convergence Analysis",
#        subtitle = "Global MPSA vs Number of Trees",
#        x = "Number of Trees", y = "Global MPSA") +
#   theme_minimal()

# === 4. ê³µê°„ íŒ¨í„´ ì‹œê°í™” ===
# 
# # MPSA ê³µê°„ ë¶„í¬ ì§€ë„
# franklin_results <- franklin
# franklin_results$mpsa <- mpsa_values
# franklin_results$mpsa_category <- cut(
#   mpsa_values,
#   breaks = quantile(mpsa_values, c(0, 0.2, 0.4, 0.6, 0.8, 1)),
#   labels = c("Very Low", "Low", "Medium", "High", "Very High"),
#   include.lowest = TRUE
# )
# 
# # === ì´ë¡ ì  ê²€ì¦ ê²°ê³¼ ì‹œê°í™” (tmap 4.1 ë²„ì „) ===
# # library(tmap)
# # spatial_map <- tm_shape(franklin_results) +
# #   tm_fill(
# #     fill = "mpsa_category",
# #     fill.scale = tm_scale_categorical(
# #       values = c("Strong Hotspot" = "#d73027", "Hotspot" = "#fc8d59",
# #                  "Not Significant" = "#ffffbf", "Coldspot" = "#91bfdb", 
# #                  "Strong Coldspot" = "#4575b4")
# #     ),
# #     fill.legend = tm_legend(title = "MPSA Category")
# #   ) +
# #   tm_borders(alpha = 0.3) +
# #   tm_layout(
# #     title = "MPSA Spatial Distribution",
# #     title.position = c("center", "top"),
# #     legend.position = c("right", "bottom")
# #   )

# === 5. ì´ë¡ ì  ì˜ˆì¸¡ vs ì‹¤ì œ ê²°ê³¼ ë¹„êµ ===
# 
# # ì´ë¡ ì  ì˜ˆì¸¡ ê²€ì¦
# theoretical_predictions <- verify_theoretical_predictions(P, W, numeric_data)
# 
# # ì˜ˆì¸¡ vs ì‹¤ì œ ì‹œê°í™”
# prediction_df <- data.frame(
#   theoretical = theoretical_predictions$expected_mpsa,
#   observed = mpsa_values,
#   region_id = 1:length(mpsa_values)
# )
# 
# p5 <- ggplot(prediction_df, aes(x = theoretical, y = observed)) +
#   geom_point(alpha = 0.6, color = "darkgreen") +
#   geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
#   geom_smooth(method = "lm", se = TRUE, color = "blue") +
#   labs(title = "Theoretical vs Observed MPSA",
#        x = "Theoretical Prediction", y = "Observed MPSA") +
#   theme_minimal()

# === 6. ê²°ê³¼ ì €ì¥ ë° ìš”ì•½ ë³´ê³ ì„œ ===
# 
# # ëª¨ë“  ì‹œê°í™” ê²°í•©
# library(patchwork)
# combined_plot <- (p1 + p2) / (p3 + p4) / p5
# 
# # ê²°ê³¼ ì €ì¥
# if (!dir.exists("output/theoretical_analysis")) {
#   dir.create("output/theoretical_analysis", recursive = TRUE)
# }
# 
# ggsave("output/theoretical_analysis/proximity_distribution.png", p1, width = 8, height = 6)
# ggsave("output/theoretical_analysis/mpsa_distribution.png", p2, width = 8, height = 6)
# ggsave("output/theoretical_analysis/bounds_verification.png", p3, width = 8, height = 6)
# ggsave("output/theoretical_analysis/convergence_analysis.png", p4, width = 8, height = 6)
# ggsave("output/theoretical_analysis/prediction_validation.png", p5, width = 8, height = 6)
# ggsave("output/theoretical_analysis/combined_analysis.png", combined_plot, width = 16, height = 12)
# 
# # ê³µê°„ ì§€ë„ ì €ì¥
# tmap_save(spatial_map, "output/theoretical_analysis/spatial_distribution.png")
# 
# # ìˆ˜ì¹˜ ê²°ê³¼ ì €ì¥
# write.csv(theoretical_results$summary, "output/theoretical_analysis/theoretical_summary.csv", row.names = FALSE)
# write.csv(convergence_results, "output/theoretical_analysis/convergence_results.csv", row.names = FALSE)
# write.csv(prediction_df, "output/theoretical_analysis/prediction_validation.csv", row.names = FALSE)
# 
# # ìµœì¢… ìš”ì•½ ì¶œë ¥
# cat("=== ì´ë¡ ì  ë¶„ì„ ì™„ë£Œ ===\n")
# cat("ğŸ“Š ì£¼ìš” ê²°ê³¼:\n")
# cat(sprintf("  - MPSA ë²”ìœ„: [%.4f, %.4f]\n", min(mpsa_values), max(mpsa_values)))
# cat(sprintf("  - LISA ì¡°ê±´ ë§Œì¡±: %s\n", 
#             ifelse(theoretical_results$lisa_condition_satisfied, "Yes", "No")))
# cat(sprintf("  - ëŒ€ì¹­ì„± ë§Œì¡±: %s\n", 
#             ifelse(theoretical_results$symmetry_satisfied, "Yes", "No")))
# cat("ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: output/theoretical_analysis/\n")
# cat("ğŸ¯ ì´ë¡ ì  ê²€ì¦ ì™„ë£Œ!\n") 
